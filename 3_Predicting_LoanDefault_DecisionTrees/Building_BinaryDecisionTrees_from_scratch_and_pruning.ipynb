{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building binary decision trees from scratch and analyzing effects of regularizations\n",
    "\n",
    "\n",
    "In this project, I use past data from peer-to-peer lending company the LeandingClub, to predict whether a future loan is likely to be paid off or default. \n",
    "\n",
    "I use this dataset to practice implementing decesion tree from scratch and to play with various regularization methods.\n",
    "\n",
    "- implement decision tree with numpy and pandas\n",
    "- implement various methods of regularization to prevent overfitting\n",
    "- use the loan defaults data to analysis the effect of limiting (1) maximum tree depth (2) minimum node size (3) minimum error gain\n",
    "\n",
    "The data is provided as part of the UW classification class. I extended the class project into a more thorough analysis presented in this notebook.\n",
    "\n",
    "Emma Yu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (8., 10.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122607, 68)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emmayu/anaconda/lib/python2.7/site-packages/pandas/io/parsers.py:1170: DtypeWarning: Columns (19,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = self._reader.read(nrows)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>sub_grade_num</th>\n",
       "      <th>delinq_2yrs_zero</th>\n",
       "      <th>pub_rec_zero</th>\n",
       "      <th>collections_12_mths_zero</th>\n",
       "      <th>short_emp</th>\n",
       "      <th>payment_inc_ratio</th>\n",
       "      <th>final_d</th>\n",
       "      <th>last_delinq_none</th>\n",
       "      <th>last_record_none</th>\n",
       "      <th>last_major_derog_none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1077501</td>\n",
       "      <td>1296599</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>4975</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65</td>\n",
       "      <td>162.87</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.14350</td>\n",
       "      <td>20141201T000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1077430</td>\n",
       "      <td>1314167</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.27</td>\n",
       "      <td>59.83</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.39320</td>\n",
       "      <td>20161201T000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077175</td>\n",
       "      <td>1313524</td>\n",
       "      <td>2400</td>\n",
       "      <td>2400</td>\n",
       "      <td>2400</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.96</td>\n",
       "      <td>84.33</td>\n",
       "      <td>C</td>\n",
       "      <td>C5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.25955</td>\n",
       "      <td>20141201T000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1076863</td>\n",
       "      <td>1277178</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.49</td>\n",
       "      <td>339.31</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.27585</td>\n",
       "      <td>20141201T000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1075269</td>\n",
       "      <td>1311441</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>7.90</td>\n",
       "      <td>156.46</td>\n",
       "      <td>A</td>\n",
       "      <td>A4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.21533</td>\n",
       "      <td>20141201T000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
       "0  1077501    1296599       5000         5000             4975   36 months   \n",
       "1  1077430    1314167       2500         2500             2500   60 months   \n",
       "2  1077175    1313524       2400         2400             2400   36 months   \n",
       "3  1076863    1277178      10000        10000            10000   36 months   \n",
       "4  1075269    1311441       5000         5000             5000   36 months   \n",
       "\n",
       "   int_rate  installment grade sub_grade          ...          sub_grade_num  \\\n",
       "0     10.65       162.87     B        B2          ...                    0.4   \n",
       "1     15.27        59.83     C        C4          ...                    0.8   \n",
       "2     15.96        84.33     C        C5          ...                    1.0   \n",
       "3     13.49       339.31     C        C1          ...                    0.2   \n",
       "4      7.90       156.46     A        A4          ...                    0.8   \n",
       "\n",
       "  delinq_2yrs_zero pub_rec_zero  collections_12_mths_zero short_emp  \\\n",
       "0                1            1                         1         0   \n",
       "1                1            1                         1         1   \n",
       "2                1            1                         1         0   \n",
       "3                1            1                         1         0   \n",
       "4                1            1                         1         0   \n",
       "\n",
       "  payment_inc_ratio          final_d last_delinq_none last_record_none  \\\n",
       "0           8.14350  20141201T000000                1                1   \n",
       "1           2.39320  20161201T000000                1                1   \n",
       "2           8.25955  20141201T000000                1                1   \n",
       "3           8.27585  20141201T000000                0                1   \n",
       "4           5.21533  20141201T000000                1                1   \n",
       "\n",
       "  last_major_derog_none  \n",
       "0                     1  \n",
       "1                     1  \n",
       "2                     1  \n",
       "3                     1  \n",
       "4                     1  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans = pd.read_csv('lending-club-data.csv') \n",
    "print loans.shape\n",
    "loans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of bad loans =  23150\n",
      "bad loan rate =  0.188814668004\n",
      "good loan rate =  0.811185331996\n"
     ]
    }
   ],
   "source": [
    "num_bad = (loans['bad_loans'] == 1).sum()\n",
    "num_total = loans['bad_loans'].count()\n",
    "print 'number of bad loans = ', num_bad\n",
    "print 'bad loan rate = ', float(num_bad)/num_total\n",
    "print 'good loan rate = ', 1-float(num_bad)/num_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For the purpose of this exercise, we only consider 4 features\n",
    "\n",
    "features = ['grade',              # grade of the loan\n",
    "            'term',               # the term of the loan\n",
    "            'home_ownership',     # home_ownership status: own, mortgage or rent\n",
    "            'emp_length',         # number of years of employment\n",
    "           ]\n",
    "target = 'bad_loans'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "      <th>term</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>bad_loans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>36 months</td>\n",
       "      <td>RENT</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>60 months</td>\n",
       "      <td>RENT</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>36 months</td>\n",
       "      <td>RENT</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>36 months</td>\n",
       "      <td>RENT</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>36 months</td>\n",
       "      <td>RENT</td>\n",
       "      <td>3 years</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  grade        term home_ownership emp_length  bad_loans\n",
       "0     B   36 months           RENT  10+ years          0\n",
       "1     C   60 months           RENT   < 1 year          1\n",
       "2     C   36 months           RENT  10+ years          0\n",
       "3     C   36 months           RENT  10+ years          0\n",
       "4     A   36 months           RENT    3 years          0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the feature columns and target column\n",
    "loans = loans[features + [target]]\n",
    "loans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "The goal to make a binary decision tree, so we need preprocess categorical variables and make dummy variables for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's try this again with get dummies \n",
    "loans = pd.get_dummies(loans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loans.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now let's separate the training and validation data. \n",
    "import json\n",
    "with open('module-5-assignment-2-train-idx.json') as train_file:    \n",
    "    train_index = json.load(train_file)\n",
    "with open('module-5-assignment-2-test-idx.json') as valid_file:    \n",
    "    valid_index = json.load(valid_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37224\n",
      "9284\n"
     ]
    }
   ],
   "source": [
    "print len(train_index)\n",
    "print len(valid_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data= loans.iloc[train_index]\n",
    "valid_data= loans.iloc[valid_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = [col for col in train_data.columns if col not in ['bad_loans']]\n",
    "train_x = train_data[cols]\n",
    "train_y = train_data['bad_loans']\n",
    "\n",
    "cols = [col for col in valid_data.columns if col not in ['bad_loans']]\n",
    "valid_x = valid_data[cols]\n",
    "valid_y = valid_data['bad_loans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grade_A',\n",
       " 'grade_B',\n",
       " 'grade_C',\n",
       " 'grade_D',\n",
       " 'grade_E',\n",
       " 'grade_F',\n",
       " 'grade_G',\n",
       " 'term_ 36 months',\n",
       " 'term_ 60 months',\n",
       " 'home_ownership_MORTGAGE',\n",
       " 'home_ownership_OTHER',\n",
       " 'home_ownership_OWN',\n",
       " 'home_ownership_RENT',\n",
       " 'emp_length_1 year',\n",
       " 'emp_length_10+ years',\n",
       " 'emp_length_2 years',\n",
       " 'emp_length_3 years',\n",
       " 'emp_length_4 years',\n",
       " 'emp_length_5 years',\n",
       " 'emp_length_6 years',\n",
       " 'emp_length_7 years',\n",
       " 'emp_length_8 years',\n",
       " 'emp_length_9 years',\n",
       " 'emp_length_< 1 year',\n",
       " 'emp_length_n/a']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def num_mistakes(labels):\n",
    "    '''\n",
    "    for one node, count the number of mistakes for a majority classifer\n",
    "    '''\n",
    "    # corner case, empty variable passed\n",
    "    if len(labels) == 0:\n",
    "        return 0\n",
    "    \n",
    "    num_bad = (labels == 1).sum()\n",
    "    num_good = (labels == 0).sum()\n",
    "    return min(num_bad, num_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pick_feature(data, features, labels):\n",
    "    '''\n",
    "    For one node in the tree, loop through features and pick the one with \n",
    "    smallest splitting error to split on \n",
    "    \n",
    "    Split based on error function now, let's try to impliment Gini index and entropy later\n",
    "    '''\n",
    "    min_error = len(labels)\n",
    "    fea_split = ''\n",
    "    for f in features:\n",
    "        #print f\n",
    "        group1 = data[data[f] == 1]\n",
    "        group1_labels = labels[data[f] == 1]\n",
    "        \n",
    "        group2 = data[data[f] == 0]\n",
    "        group2_labels = labels[data[f] == 0]\n",
    "        \n",
    "        error = num_mistakes(group1_labels) + num_mistakes(group2_labels)\n",
    "        \n",
    "        if error < min_error:\n",
    "            min_error = error\n",
    "            fea_split = f          \n",
    "    \n",
    "    return fea_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pick_feature(train_x, cols, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_leaf(labels):    \n",
    "    '''\n",
    "    create a leaf node for splitting recursively \n",
    "    for labels, 1 means bad loan and 0 means good loan.\n",
    "    '''\n",
    "    leaf = {'splitting_feature' : None,\n",
    "            'left' : None,\n",
    "            'right' : None,\n",
    "            'is_leaf':  True}   \n",
    "   \n",
    "    # Count the number of data points that are 1 and 0 in this node.\n",
    "    num_pos = len(labels[labels == 1])\n",
    "    num_neg = len(labels[labels == 0])    \n",
    "\n",
    "    # For the leaf node, set the prediction to be the majority class.\n",
    "    # Store the predicted class (1 or -1) in leaf['prediction']\n",
    "    if num_pos > num_neg:\n",
    "        leaf['prediction'] =  1       \n",
    "    else:\n",
    "        leaf['prediction'] =  0            \n",
    "    return leaf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At each split we want to drop one feature\n",
    "At each split we double the number of leave nodes (does it mean we need to create a new round of leave nodes?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decision_tree_create(data, features, labels, current_depth = 0, max_depth = 10):\n",
    "    ''' Build the tree in a depth first way'''\n",
    "\n",
    "    remaining_features = features[:] \n",
    "\n",
    "    print \"--------------------------------------------------------------------\"\n",
    "    print \"Subtree, depth = %s (%s data points).\" % (current_depth, len(labels))\n",
    "    \n",
    "    # Stopping condition 1 - if the node is pure\n",
    "    if  num_mistakes(labels)== 0: \n",
    "        print \"Stop splitting because the node is pure\"     \n",
    "        return create_leaf(labels)\n",
    "    \n",
    "    # Stopping condition 2 - running out of features\n",
    "    if remaining_features == []:   \n",
    "        print \"Stop splitting because no feature is available\"    \n",
    "        return create_leaf(labels)  \n",
    "\n",
    "    # Stopping condition 3 - if maximum depth has reached\n",
    "    if current_depth >= max_depth:  \n",
    "        print \"Stop splitting because the tree has reached the maximum depth.\"\n",
    "        return create_leaf(labels)\n",
    "\n",
    "    # Split the tree on the feature that minimizes the error\n",
    "    # note that the features and ys are stored separately \n",
    "    # we want to make sure to split on both\n",
    "    splitting_feature = pick_feature(data, features, labels)\n",
    "    left_split = data[data[splitting_feature] == 0]\n",
    "    left_labels = labels[data[splitting_feature] == 0]\n",
    "    right_split = data[data[splitting_feature] == 1] \n",
    "    right_labels = labels[data[splitting_feature] == 1] \n",
    "    \n",
    "    remaining_features.remove(splitting_feature)\n",
    "    print \"Split on feature %s. (%s, %s)\"%(splitting_feature, len(left_split), len(right_split))\n",
    "    \n",
    "    # Create a leaf node if the split is \"perfect\"\n",
    "    if len(left_split) == len(data):\n",
    "        print \"Creating leaf node.\"\n",
    "        return create_leaf(left_labels)\n",
    "    if len(right_split) == len(data):\n",
    "        print \"Creating leaf node.\"\n",
    "        return create_leaf(right_labels)\n",
    "\n",
    "        \n",
    "    # Repeat (recurse) on left and right subtrees\n",
    "    left_tree = decision_tree_create(left_split, remaining_features, left_labels, current_depth + 1, max_depth)        \n",
    "    right_tree = decision_tree_create(right_split, remaining_features, right_labels, current_depth + 1, max_depth) \n",
    "\n",
    "    return {'is_leaf'          : False, \n",
    "            'prediction'       : None,\n",
    "            'splitting_feature': splitting_feature,\n",
    "            'left'             : left_tree, \n",
    "            'right'            : right_tree}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "Split on feature term_ 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9223 data points).\n",
      "Split on feature grade_A. (9122, 101)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9122 data points).\n",
      "Split on feature grade_B. (8074, 1048)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (8074 data points).\n",
      "Split on feature grade_C. (5884, 2190)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (5884 data points).\n",
      "Split on feature grade_D. (3826, 2058)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (3826 data points).\n",
      "Split on feature grade_E. (1693, 2133)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1693 data points).\n",
      "Stop splitting because the tree has reached the maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2133 data points).\n",
      "Stop splitting because the tree has reached the maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (2058 data points).\n",
      "Split on feature grade_E. (2058, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (2190 data points).\n",
      "Split on feature grade_D. (2190, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1048 data points).\n",
      "Split on feature emp_length_5 years. (969, 79)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (969 data points).\n",
      "Split on feature grade_C. (969, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (79 data points).\n",
      "Split on feature home_ownership_MORTGAGE. (34, 45)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (34 data points).\n",
      "Split on feature grade_C. (34, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (45 data points).\n",
      "Split on feature grade_C. (45, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (101 data points).\n",
      "Split on feature emp_length_n/a. (96, 5)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (96 data points).\n",
      "Split on feature emp_length_< 1 year. (85, 11)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (85 data points).\n",
      "Split on feature grade_B. (85, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (11 data points).\n",
      "Split on feature grade_B. (11, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (5 data points).\n",
      "Split on feature grade_B. (5, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (28001 data points).\n",
      "Split on feature grade_D. (23300, 4701)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (23300 data points).\n",
      "Split on feature grade_E. (22024, 1276)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (22024 data points).\n",
      "Split on feature grade_F. (21666, 358)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (21666 data points).\n",
      "Split on feature emp_length_n/a. (20734, 932)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (20734 data points).\n",
      "Split on feature grade_G. (20638, 96)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (20638 data points).\n",
      "Stop splitting because the tree has reached the maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (96 data points).\n",
      "Stop splitting because the tree has reached the maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (932 data points).\n",
      "Split on feature grade_A. (702, 230)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (702 data points).\n",
      "Stop splitting because the tree has reached the maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (230 data points).\n",
      "Stop splitting because the tree has reached the maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (358 data points).\n",
      "Split on feature emp_length_8 years. (347, 11)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (347 data points).\n",
      "Split on feature grade_A. (347, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (11 data points).\n",
      "Split on feature home_ownership_OWN. (9, 2)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (9 data points).\n",
      "Stop splitting because the tree has reached the maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2 data points).\n",
      "Stop splitting because the node is pure\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1276 data points).\n",
      "Split on feature grade_A. (1276, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (4701 data points).\n",
      "Split on feature grade_A. (4701, 0)\n",
      "Creating leaf node.\n"
     ]
    }
   ],
   "source": [
    "tree = decision_tree_create(train_x, cols, train_y, current_depth = 0, max_depth = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_leaf': False,\n",
       " 'left': {'is_leaf': False,\n",
       "  'left': {'is_leaf': False,\n",
       "   'left': {'is_leaf': False,\n",
       "    'left': {'is_leaf': False,\n",
       "     'left': {'is_leaf': False,\n",
       "      'left': {'is_leaf': True,\n",
       "       'left': None,\n",
       "       'prediction': 1,\n",
       "       'right': None,\n",
       "       'splitting_feature': None},\n",
       "      'prediction': None,\n",
       "      'right': {'is_leaf': True,\n",
       "       'left': None,\n",
       "       'prediction': 1,\n",
       "       'right': None,\n",
       "       'splitting_feature': None},\n",
       "      'splitting_feature': 'grade_E'},\n",
       "     'prediction': None,\n",
       "     'right': {'is_leaf': True,\n",
       "      'left': None,\n",
       "      'prediction': 1,\n",
       "      'right': None,\n",
       "      'splitting_feature': None},\n",
       "     'splitting_feature': 'grade_D'},\n",
       "    'prediction': None,\n",
       "    'right': {'is_leaf': True,\n",
       "     'left': None,\n",
       "     'prediction': 1,\n",
       "     'right': None,\n",
       "     'splitting_feature': None},\n",
       "    'splitting_feature': 'grade_C'},\n",
       "   'prediction': None,\n",
       "   'right': {'is_leaf': False,\n",
       "    'left': {'is_leaf': True,\n",
       "     'left': None,\n",
       "     'prediction': 1,\n",
       "     'right': None,\n",
       "     'splitting_feature': None},\n",
       "    'prediction': None,\n",
       "    'right': {'is_leaf': False,\n",
       "     'left': {'is_leaf': True,\n",
       "      'left': None,\n",
       "      'prediction': 0,\n",
       "      'right': None,\n",
       "      'splitting_feature': None},\n",
       "     'prediction': None,\n",
       "     'right': {'is_leaf': True,\n",
       "      'left': None,\n",
       "      'prediction': 1,\n",
       "      'right': None,\n",
       "      'splitting_feature': None},\n",
       "     'splitting_feature': 'home_ownership_MORTGAGE'},\n",
       "    'splitting_feature': 'emp_length_5 years'},\n",
       "   'splitting_feature': 'grade_B'},\n",
       "  'prediction': None,\n",
       "  'right': {'is_leaf': False,\n",
       "   'left': {'is_leaf': False,\n",
       "    'left': {'is_leaf': True,\n",
       "     'left': None,\n",
       "     'prediction': 0,\n",
       "     'right': None,\n",
       "     'splitting_feature': None},\n",
       "    'prediction': None,\n",
       "    'right': {'is_leaf': True,\n",
       "     'left': None,\n",
       "     'prediction': 1,\n",
       "     'right': None,\n",
       "     'splitting_feature': None},\n",
       "    'splitting_feature': 'emp_length_< 1 year'},\n",
       "   'prediction': None,\n",
       "   'right': {'is_leaf': True,\n",
       "    'left': None,\n",
       "    'prediction': 1,\n",
       "    'right': None,\n",
       "    'splitting_feature': None},\n",
       "   'splitting_feature': 'emp_length_n/a'},\n",
       "  'splitting_feature': 'grade_A'},\n",
       " 'prediction': None,\n",
       " 'right': {'is_leaf': False,\n",
       "  'left': {'is_leaf': False,\n",
       "   'left': {'is_leaf': False,\n",
       "    'left': {'is_leaf': False,\n",
       "     'left': {'is_leaf': False,\n",
       "      'left': {'is_leaf': True,\n",
       "       'left': None,\n",
       "       'prediction': 0,\n",
       "       'right': None,\n",
       "       'splitting_feature': None},\n",
       "      'prediction': None,\n",
       "      'right': {'is_leaf': True,\n",
       "       'left': None,\n",
       "       'prediction': 1,\n",
       "       'right': None,\n",
       "       'splitting_feature': None},\n",
       "      'splitting_feature': 'grade_G'},\n",
       "     'prediction': None,\n",
       "     'right': {'is_leaf': False,\n",
       "      'left': {'is_leaf': True,\n",
       "       'left': None,\n",
       "       'prediction': 1,\n",
       "       'right': None,\n",
       "       'splitting_feature': None},\n",
       "      'prediction': None,\n",
       "      'right': {'is_leaf': True,\n",
       "       'left': None,\n",
       "       'prediction': 0,\n",
       "       'right': None,\n",
       "       'splitting_feature': None},\n",
       "      'splitting_feature': 'grade_A'},\n",
       "     'splitting_feature': 'emp_length_n/a'},\n",
       "    'prediction': None,\n",
       "    'right': {'is_leaf': False,\n",
       "     'left': {'is_leaf': True,\n",
       "      'left': None,\n",
       "      'prediction': 1,\n",
       "      'right': None,\n",
       "      'splitting_feature': None},\n",
       "     'prediction': None,\n",
       "     'right': {'is_leaf': False,\n",
       "      'left': {'is_leaf': True,\n",
       "       'left': None,\n",
       "       'prediction': 0,\n",
       "       'right': None,\n",
       "       'splitting_feature': None},\n",
       "      'prediction': None,\n",
       "      'right': {'is_leaf': True,\n",
       "       'left': None,\n",
       "       'prediction': 1,\n",
       "       'right': None,\n",
       "       'splitting_feature': None},\n",
       "      'splitting_feature': 'home_ownership_OWN'},\n",
       "     'splitting_feature': 'emp_length_8 years'},\n",
       "    'splitting_feature': 'grade_F'},\n",
       "   'prediction': None,\n",
       "   'right': {'is_leaf': True,\n",
       "    'left': None,\n",
       "    'prediction': 1,\n",
       "    'right': None,\n",
       "    'splitting_feature': None},\n",
       "   'splitting_feature': 'grade_E'},\n",
       "  'prediction': None,\n",
       "  'right': {'is_leaf': True,\n",
       "   'left': None,\n",
       "   'prediction': 1,\n",
       "   'right': None,\n",
       "   'splitting_feature': None},\n",
       "  'splitting_feature': 'grade_D'},\n",
       " 'splitting_feature': 'term_ 36 months'}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classify(tree, x, annotate = False):\n",
    "    # if the node is a leaf node.\n",
    "    if tree['is_leaf']:\n",
    "        if annotate:\n",
    "             print \"At leaf, predicting %s\" % tree['prediction']\n",
    "        return tree['prediction']\n",
    "    else:\n",
    "        # split on feature.\n",
    "        split_feature_value = x[tree['splitting_feature']]\n",
    "        if annotate:\n",
    "            print \"Split on %s = %s\" % (tree['splitting_feature'], split_feature_value)\n",
    "        if split_feature_value == 0:\n",
    "            return classify(tree['left'], x, annotate)\n",
    "        else:\n",
    "            return classify(tree['right'], x, annotate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grade_A                    0\n",
      "grade_B                    0\n",
      "grade_C                    0\n",
      "grade_D                    1\n",
      "grade_E                    0\n",
      "grade_F                    0\n",
      "grade_G                    0\n",
      "term_ 36 months            0\n",
      "term_ 60 months            1\n",
      "home_ownership_MORTGAGE    0\n",
      "home_ownership_OTHER       0\n",
      "home_ownership_OWN         0\n",
      "home_ownership_RENT        1\n",
      "emp_length_1 year          0\n",
      "emp_length_10+ years       0\n",
      "emp_length_2 years         1\n",
      "emp_length_3 years         0\n",
      "emp_length_4 years         0\n",
      "emp_length_5 years         0\n",
      "emp_length_6 years         0\n",
      "emp_length_7 years         0\n",
      "emp_length_8 years         0\n",
      "emp_length_9 years         0\n",
      "emp_length_< 1 year        0\n",
      "emp_length_n/a             0\n",
      "Name: 24, dtype: float64\n",
      "Split on term_ 36 months = 0.0\n",
      "Split on grade_A = 0.0\n",
      "Split on grade_B = 0.0\n",
      "Split on grade_C = 0.0\n",
      "Split on grade_D = 1.0\n",
      "At leaf, predicting 1\n",
      "Predicted class: 1 \n"
     ]
    }
   ],
   "source": [
    "print valid_x.iloc[0]\n",
    "print 'Predicted class: %s ' % classify(tree,valid_x.iloc[0], annotate = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(tree,valid_x.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(tree, data, ys):\n",
    "    ''' \n",
    "    Apply the classify(tree, x) to each row in the data\n",
    "    then calculate the error rate\n",
    "    '''\n",
    "    length = len(ys)\n",
    "    prediction = np.zeros(length)\n",
    "    correct = 0 \n",
    "    \n",
    "    for i in range(length):\n",
    "        prediction[i] = classify(tree, data.iloc[i])\n",
    "        if prediction[i] == ys.iloc[i]:\n",
    "            correct += 1\n",
    "            \n",
    "    error = (length-correct)/float(length)\n",
    "    return prediction, error\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 1.,  0.,  1., ...,  1.,  1.,  0.]), 0.3837785437311504)\n"
     ]
    }
   ],
   "source": [
    "print evaluate(tree, valid_x, valid_y)\n",
    "#len(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stump(tree, name = 'root'):\n",
    "    split_name = tree['splitting_feature'] # split_name is something like 'term. 36 months'\n",
    "    if split_name is None:\n",
    "        print \"(leaf, label: %s)\" % tree['prediction']\n",
    "        return None\n",
    "    print split_name\n",
    "    split_feature, split_value = split_name.split('.')\n",
    "    print '                       %s' % name\n",
    "    print '         |---------------|----------------|'\n",
    "    print '         |                                |'\n",
    "    print '         |                                |'\n",
    "    print '         |                                |'\n",
    "    print '  [{0} == 0]               [{0} == 1]    '.format(split_name)\n",
    "    print '         |                                |'\n",
    "    print '         |                                |'\n",
    "    print '         |                                |'\n",
    "    print '    (%s)                         (%s)' \\\n",
    "        % (('leaf, label: ' + str(tree['left']['prediction']) if tree['left']['is_leaf'] else 'subtree'),\n",
    "           ('leaf, label: ' + str(tree['right']['prediction']) if tree['right']['is_leaf'] else 'subtree'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function viewkeys>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.viewkeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print_stump(tree['left'], tree['splitting_feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print_stump(tree['left']['left'], tree['left']['splitting_feature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early stop to avoid over-fitting\n",
    "\n",
    "In order to prevent over-fitting, we want to implement 3 early stop conditions:\n",
    "- the tree has reached a maximum depth (inplemented already)\n",
    "- number of elements contained has reached a minimum (minimum node size)\n",
    "- do not gain enough error reduction by splitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def decision_tree_create_es(data, features, labels, current_depth = 0, max_depth = 10, min_node_size = 10, min_error_gain = 0.1):\n",
    "    ''' \n",
    "    Build the tree in a depth first way\n",
    "    es - adding two early stop conditions \n",
    "    '''\n",
    "\n",
    "    remaining_features = features[:] \n",
    "\n",
    "    #print \"--------------------------------------------------------------------\"\n",
    "    #print \"Subtree, depth = %s (%s data points).\" % (current_depth, len(labels))\n",
    "    \n",
    "    # Stopping condition 1 - if the node is pure\n",
    "    if  num_mistakes(labels)== 0: \n",
    "        #print \"Stop splitting because the node is pure\"     \n",
    "        return create_leaf(labels)\n",
    "    \n",
    "    # Stopping condition 2 - running out of features\n",
    "    if remaining_features == []:   \n",
    "        #print \"Stop splitting because no feature is available\"    \n",
    "        return create_leaf(labels)  \n",
    "\n",
    "    # Stopping condition 3 - if maximum depth has reached\n",
    "    if current_depth >= max_depth:  \n",
    "        #print \"Stop splitting because the tree has reached the maximum depth.\"\n",
    "        return create_leaf(labels)\n",
    "    \n",
    "    # Early stop condition 2 - if the minimum node size has been reached\n",
    "    if len(labels) <= min_node_size:\n",
    "        #print \"Stop splitting because the tree has reached the minimum node size.\"\n",
    "        return create_leaf(labels)\n",
    "    \n",
    "\n",
    "    # Split the tree on the feature that minimizes the error\n",
    "    # note that the features and ys are stored separately \n",
    "    # we want to make sure to split on both\n",
    "    splitting_feature = pick_feature(data, features, labels)\n",
    "    left_split = data[data[splitting_feature] == 0]\n",
    "    left_labels = labels[data[splitting_feature] == 0]\n",
    "    right_split = data[data[splitting_feature] == 1] \n",
    "    right_labels = labels[data[splitting_feature] == 1] \n",
    "    \n",
    "    # Early stop condition 3 - if the gain in error reduction is big enough\n",
    "    error_before = num_mistakes(labels)\n",
    "    error_after = num_mistakes(left_labels) + num_mistakes(right_labels)\n",
    "    if float(error_before - error_after)/len(labels) <= min_error_gain:\n",
    "        #print 'Stop splitting because not having big enough error gain'\n",
    "        return create_leaf(labels)\n",
    "\n",
    "    \n",
    "    remaining_features.remove(splitting_feature)\n",
    "    #print \"Split on feature %s. (%s, %s)\"%(splitting_feature, len(left_split), len(right_split))\n",
    "    \n",
    "    # Create a leaf node if the split is \"perfect\"\n",
    "    if len(left_split) == len(data):\n",
    "        #print \"Creating leaf node.\"\n",
    "        return create_leaf(left_labels)\n",
    "    if len(right_split) == len(data):\n",
    "        #print \"Creating leaf node.\"\n",
    "        return create_leaf(right_labels)\n",
    "\n",
    "        \n",
    "    # Repeat (recurse) on left and right subtrees\n",
    "    left_tree = decision_tree_create_es(left_split, remaining_features, left_labels, current_depth + 1, max_depth, min_node_size, min_error_gain)        \n",
    "    right_tree = decision_tree_create_es(right_split, remaining_features, right_labels, current_depth + 1, max_depth, min_node_size, min_error_gain) \n",
    "\n",
    "    return {'is_leaf'          : False, \n",
    "            'prediction'       : None,\n",
    "            'splitting_feature': splitting_feature,\n",
    "            'left'             : left_tree, \n",
    "            'right'            : right_tree}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37224\n",
      "9284\n"
     ]
    }
   ],
   "source": [
    "# for the model with early stop conditions, we want to use a different sub-sample just for fun.\n",
    "import json\n",
    "with open('module-6-assignment-train-idx.json') as train_file_es:    \n",
    "    train_index_es = json.load(train_file_es)\n",
    "with open('module-6-assignment-validation-idx.json') as valid_file_es:    \n",
    "    valid_index_es = json.load(valid_file_es)\n",
    "    \n",
    "print len(train_index_es)\n",
    "print len(valid_index_es)\n",
    "\n",
    "train_data_es= loans.iloc[train_index_es]\n",
    "valid_data_es= loans.iloc[valid_index_es]\n",
    "\n",
    "cols = [col for col in train_data_es.columns if col not in ['bad_loans']]\n",
    "train_x_es = train_data_es[cols]\n",
    "train_y_es = train_data_es['bad_loans']\n",
    "\n",
    "cols = [col for col in valid_data_es.columns if col not in ['bad_loans']]\n",
    "valid_x_es = valid_data_es[cols]\n",
    "valid_y_es = valid_data_es['bad_loans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37224, 25)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_es.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train a model with minimum node size of 100. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "Split on feature term_ 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9223 data points).\n",
      "Split on feature grade_A. (9122, 101)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9122 data points).\n",
      "Stop splitting because not having big enough error gain\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (101 data points).\n",
      "Split on feature emp_length_n/a. (96, 5)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (96 data points).\n",
      "Stop splitting because the tree has reached the minimum node size.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (5 data points).\n",
      "Stop splitting because the tree has reached the minimum node size.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (28001 data points).\n",
      "Split on feature grade_D. (23300, 4701)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (23300 data points).\n",
      "Split on feature grade_E. (22024, 1276)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (22024 data points).\n",
      "Split on feature grade_F. (21666, 358)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (21666 data points).\n",
      "Split on feature emp_length_n/a. (20734, 932)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (20734 data points).\n",
      "Split on feature grade_G. (20638, 96)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (20638 data points).\n",
      "Stop splitting because the tree has reached the maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (96 data points).\n",
      "Stop splitting because the tree has reached the maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (932 data points).\n",
      "Split on feature grade_A. (702, 230)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (702 data points).\n",
      "Stop splitting because the tree has reached the maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (230 data points).\n",
      "Stop splitting because the tree has reached the maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (358 data points).\n",
      "Split on feature emp_length_8 years. (347, 11)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (347 data points).\n",
      "Stop splitting because not having big enough error gain\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (11 data points).\n",
      "Stop splitting because the tree has reached the minimum node size.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1276 data points).\n",
      "Stop splitting because not having big enough error gain\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (4701 data points).\n",
      "Stop splitting because not having big enough error gain\n"
     ]
    }
   ],
   "source": [
    "tree_es = decision_tree_create_es(train_x_es, cols, train_y_es, max_depth = 6, min_node_size = 100, min_error_gain=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grade_A                    0\n",
      "grade_B                    0\n",
      "grade_C                    0\n",
      "grade_D                    1\n",
      "grade_E                    0\n",
      "grade_F                    0\n",
      "grade_G                    0\n",
      "term_ 36 months            0\n",
      "term_ 60 months            1\n",
      "home_ownership_MORTGAGE    0\n",
      "home_ownership_OTHER       0\n",
      "home_ownership_OWN         0\n",
      "home_ownership_RENT        1\n",
      "emp_length_1 year          0\n",
      "emp_length_10+ years       0\n",
      "emp_length_2 years         1\n",
      "emp_length_3 years         0\n",
      "emp_length_4 years         0\n",
      "emp_length_5 years         0\n",
      "emp_length_6 years         0\n",
      "emp_length_7 years         0\n",
      "emp_length_8 years         0\n",
      "emp_length_9 years         0\n",
      "emp_length_< 1 year        0\n",
      "emp_length_n/a             0\n",
      "Name: 24, dtype: float64\n",
      "Split on term_ 36 months = 0.0\n",
      "Split on grade_A = 0.0\n",
      "At leaf, predicting 1\n",
      "Predicted class: 1 \n"
     ]
    }
   ],
   "source": [
    "print valid_x_es.iloc[0]\n",
    "print 'Predicted class: %s ' % classify(tree_es,valid_x_es.iloc[0], annotate = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "Split on feature term_ 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9223 data points).\n",
      "Split on feature grade_A. (9122, 101)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9122 data points).\n",
      "Split on feature grade_B. (8074, 1048)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (8074 data points).\n",
      "Split on feature grade_C. (5884, 2190)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (5884 data points).\n",
      "Split on feature grade_D. (3826, 2058)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (3826 data points).\n",
      "Split on feature grade_E. (1693, 2133)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1693 data points).\n",
      "Stop splitting because the tree has reached the maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2133 data points).\n",
      "Stop splitting because the tree has reached the maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (2058 data points).\n",
      "Split on feature grade_E. (2058, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (2190 data points).\n",
      "Split on feature grade_D. (2190, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1048 data points).\n",
      "Split on feature emp_length_5 years. (969, 79)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (969 data points).\n",
      "Split on feature grade_C. (969, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (79 data points).\n",
      "Split on feature home_ownership_MORTGAGE. (34, 45)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (34 data points).\n",
      "Split on feature grade_C. (34, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (45 data points).\n",
      "Split on feature grade_C. (45, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (101 data points).\n",
      "Split on feature emp_length_n/a. (96, 5)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (96 data points).\n",
      "Split on feature emp_length_< 1 year. (85, 11)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (85 data points).\n",
      "Split on feature grade_B. (85, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (11 data points).\n",
      "Split on feature grade_B. (11, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (5 data points).\n",
      "Split on feature grade_B. (5, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (28001 data points).\n",
      "Split on feature grade_D. (23300, 4701)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (23300 data points).\n",
      "Split on feature grade_E. (22024, 1276)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (22024 data points).\n",
      "Split on feature grade_F. (21666, 358)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (21666 data points).\n",
      "Split on feature emp_length_n/a. (20734, 932)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (20734 data points).\n",
      "Split on feature grade_G. (20638, 96)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (20638 data points).\n",
      "Stop splitting because the tree has reached the maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (96 data points).\n",
      "Stop splitting because the tree has reached the maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (932 data points).\n",
      "Split on feature grade_A. (702, 230)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (702 data points).\n",
      "Stop splitting because the tree has reached the maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (230 data points).\n",
      "Stop splitting because the tree has reached the maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (358 data points).\n",
      "Split on feature emp_length_8 years. (347, 11)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (347 data points).\n",
      "Split on feature grade_A. (347, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (11 data points).\n",
      "Split on feature home_ownership_OWN. (9, 2)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (9 data points).\n",
      "Stop splitting because the tree has reached the maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2 data points).\n",
      "Stop splitting because the node is pure\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1276 data points).\n",
      "Split on feature grade_A. (1276, 0)\n",
      "Creating leaf node.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (4701 data points).\n",
      "Split on feature grade_A. (4701, 0)\n",
      "Creating leaf node.\n"
     ]
    }
   ],
   "source": [
    "# build a tree without early stop condition 2\n",
    "tree_comparison = decision_tree_create_es(train_x_es, cols, train_y_es, max_depth = 6, min_node_size = 0, min_error_gain=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grade_A                    0\n",
      "grade_B                    0\n",
      "grade_C                    0\n",
      "grade_D                    1\n",
      "grade_E                    0\n",
      "grade_F                    0\n",
      "grade_G                    0\n",
      "term_ 36 months            0\n",
      "term_ 60 months            1\n",
      "home_ownership_MORTGAGE    0\n",
      "home_ownership_OTHER       0\n",
      "home_ownership_OWN         0\n",
      "home_ownership_RENT        1\n",
      "emp_length_1 year          0\n",
      "emp_length_10+ years       0\n",
      "emp_length_2 years         1\n",
      "emp_length_3 years         0\n",
      "emp_length_4 years         0\n",
      "emp_length_5 years         0\n",
      "emp_length_6 years         0\n",
      "emp_length_7 years         0\n",
      "emp_length_8 years         0\n",
      "emp_length_9 years         0\n",
      "emp_length_< 1 year        0\n",
      "emp_length_n/a             0\n",
      "Name: 24, dtype: float64\n",
      "Split on term_ 36 months = 0.0\n",
      "Split on grade_A = 0.0\n",
      "Split on grade_B = 0.0\n",
      "Split on grade_C = 0.0\n",
      "Split on grade_D = 1.0\n",
      "At leaf, predicting 1\n",
      "Predicted class: 1 \n"
     ]
    }
   ],
   "source": [
    "print valid_x_es.iloc[0]\n",
    "print 'Predicted class: %s ' % classify(tree_comparison,valid_x_es.iloc[0], annotate = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare the results between the previous tree we built without early minimum node size and the one with minimum node size of 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min node size 100, train:  (array([ 1.,  1.,  1., ...,  0.,  1.,  1.]), 0.38203846980442724)\n",
      "min node size 100, valid:  (array([ 1.,  0.,  1., ...,  1.,  1.,  0.]), 0.38367083153813014)\n",
      "min node size 0, train:  (array([ 1.,  1.,  1., ...,  0.,  1.,  1.]), 0.38185041908446166)\n",
      "min node size 0, valid:  (array([ 1.,  0.,  1., ...,  1.,  1.,  0.]), 0.3837785437311504)\n"
     ]
    }
   ],
   "source": [
    "#the new tree \n",
    "print 'min node size 100, train: ',evaluate(tree_es, train_x_es, train_y_es)\n",
    "print 'min node size 100, valid: ',evaluate(tree_es, valid_x_es, valid_y_es)\n",
    "# the old tree\n",
    "print 'min node size 0, train: ', evaluate(tree_comparison, train_x_es, train_y_es)\n",
    "print 'min node size 0, valid: ', evaluate(tree_comparison, valid_x_es, valid_y_es)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the old tree with minimum node size 0 has smaller training error but higher validation error. This could be a sign of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To further study the effect of each parameter, let's build three groups of trees. \n",
    "In the first group, let's isolate the effect of maximum tree depth, and look at the error rate of trees with maxinum depth of 2, 6, and 14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameter stud, lets train a suite of trees\n",
    "tree_depth2 = decision_tree_create_es(train_x_es, cols, train_y_es, max_depth = 2, min_node_size = 0, min_error_gain=-1)\n",
    "tree_depth6 = decision_tree_create_es(train_x_es, cols, train_y_es, max_depth = 6, min_node_size = 0, min_error_gain=-1)\n",
    "tree_depth14 = decision_tree_create_es(train_x_es, cols, train_y_es, max_depth = 14, min_node_size = 0, min_error_gain=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level2, train:  (array([ 1.,  1.,  1., ...,  0.,  1.,  1.]), 0.40003761014399314)\n",
      "level2, valid:  (array([ 1.,  0.,  1., ...,  1.,  0.,  0.]), 0.3981042654028436)\n",
      "level6, train:  (array([ 1.,  1.,  1., ...,  0.,  1.,  1.]), 0.38185041908446166)\n",
      "level6, valid:  (array([ 1.,  0.,  1., ...,  1.,  1.,  0.]), 0.3837785437311504)\n",
      "level14, train:  (array([ 1.,  1.,  1., ...,  0.,  1.,  1.]), 0.3761820330969267)\n",
      "level14, valid:  (array([ 1.,  0.,  1., ...,  1.,  1.,  0.]), 0.37731581214993537)\n"
     ]
    }
   ],
   "source": [
    "# 2 level tree\n",
    "print 'level2, train: ',evaluate(tree_depth2, train_x_es, train_y_es)\n",
    "print 'level2, valid: ',evaluate(tree_depth2, valid_x_es, valid_y_es)\n",
    "\n",
    "# 6 level tree\n",
    "print 'level6, train: ',evaluate(tree_depth6, train_x_es, train_y_es)\n",
    "print 'level6, valid: ',evaluate(tree_depth6, valid_x_es, valid_y_es)\n",
    "\n",
    "# 14 level tree\n",
    "print 'level14, train: ',evaluate(tree_depth14, train_x_es, train_y_es)\n",
    "print 'level14, valid: ',evaluate(tree_depth14, valid_x_es, valid_y_es)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see both the training error and the validation error decrease with tree depth in this example. This means even with a tree of depth 14, we are still making progress by building a larger tree, and overfitting does not seem to be an issue here.\n",
    "\n",
    "\n",
    "\n",
    "#### Now let's look at error reduction.\n",
    "We consider trees with minimum error reduction of -1, 0 and 5. This means we will not split a node unless the maximum gain on error is larger than this minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree_error1 = decision_tree_create_es(train_x_es, cols, train_y_es, max_depth = 6, min_node_size = 0, min_error_gain=-1)\n",
    "tree_error2 = decision_tree_create_es(train_x_es, cols, train_y_es, max_depth = 6, min_node_size = 0, min_error_gain=0)\n",
    "tree_error3 = decision_tree_create_es(train_x_es, cols, train_y_es, max_depth = 6, min_node_size = 0, min_error_gain=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error reduction = -1, train:  (array([ 1.,  1.,  1., ...,  0.,  1.,  1.]), 0.38185041908446166)\n",
      "error reduction = -1, valid:  (array([ 1.,  0.,  1., ...,  1.,  1.,  0.]), 0.3837785437311504)\n",
      "error reduction = 0, train:  (array([ 1.,  1.,  1., ...,  0.,  1.,  1.]), 0.3819578766387277)\n",
      "error reduction = 0, valid:  (array([ 1.,  0.,  1., ...,  1.,  1.,  0.]), 0.3837785437311504)\n",
      "error reduction = 5, train:  (array([ 0.,  0.,  0., ...,  0.,  0.,  0.]), 0.4963464431549538)\n",
      "error reduction = 5, valid:  (array([ 0.,  0.,  0., ...,  0.,  0.,  0.]), 0.503446790176648)\n"
     ]
    }
   ],
   "source": [
    "print 'error reduction = -1, train: ',evaluate(tree_error1, train_x_es, train_y_es)\n",
    "print 'error reduction = -1, valid: ',evaluate(tree_error1, valid_x_es, valid_y_es)\n",
    "\n",
    "print 'error reduction = 0, train: ',evaluate(tree_error2, train_x_es, train_y_es)\n",
    "print 'error reduction = 0, valid: ',evaluate(tree_error2, valid_x_es, valid_y_es)\n",
    "\n",
    "print 'error reduction = 5, train: ',evaluate(tree_error3, train_x_es, train_y_es)\n",
    "print 'error reduction = 5, valid: ',evaluate(tree_error3, valid_x_es, valid_y_es)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree_node1 = decision_tree_create_es(train_x_es, cols, train_y_es, max_depth = 6, min_node_size = 0, min_error_gain=-1)\n",
    "tree_node2 = decision_tree_create_es(train_x_es, cols, train_y_es, max_depth = 6, min_node_size = 2000, min_error_gain=-1)\n",
    "tree_node3 = decision_tree_create_es(train_x_es, cols, train_y_es, max_depth = 6, min_node_size = 50000, min_error_gain=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min node size = 0, train:  (array([ 1.,  1.,  1., ...,  0.,  1.,  1.]), 0.38185041908446166)\n",
      "min node size = 0, valid:  (array([ 1.,  0.,  1., ...,  1.,  1.,  0.]), 0.3837785437311504)\n",
      "min node size = 2000, train:  (array([ 1.,  1.,  1., ...,  0.,  1.,  1.]), 0.3837040618955513)\n",
      "min node size = 2000, valid:  (array([ 1.,  0.,  1., ...,  1.,  1.,  1.]), 0.38453252908229213)\n",
      "min node size = 50000, train:  (array([ 0.,  0.,  0., ...,  0.,  0.,  0.]), 0.4963464431549538)\n",
      "min node size = 50000, valid:  (array([ 0.,  0.,  0., ...,  0.,  0.,  0.]), 0.503446790176648)\n"
     ]
    }
   ],
   "source": [
    "print 'min node size = 0, train: ',evaluate(tree_node1, train_x_es, train_y_es)\n",
    "print 'min node size = 0, valid: ',evaluate(tree_node1, valid_x_es, valid_y_es)\n",
    "\n",
    "print 'min node size = 2000, train: ',evaluate(tree_node2, train_x_es, train_y_es)\n",
    "print 'min node size = 2000, valid: ',evaluate(tree_node2, valid_x_es, valid_y_es)\n",
    "\n",
    "print 'min node size = 50000, train: ',evaluate(tree_node3, train_x_es, train_y_es)\n",
    "print 'min node size = 50000, valid: ',evaluate(tree_node3, valid_x_es, valid_y_es)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
